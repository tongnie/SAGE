<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="SAGE: Steerable Adversarial Scenario Generation through Test-Time Preference Alignment">
  <meta name="description" content="Official project page for SAGE, a novel framework that enables fine-grained, test-time control over the trade-off between adversariality and realism in autonomous driving scenario generation without any retraining.">
  <meta name="keywords" content="adversarial scenario generation, autonomous driving, safety assessment, preference alignment, reinforcement learning, test-time control, steerable generation">
  <meta name="author" content="Tong Nie, Yuewen Mei, Yihong Tang, Junlin He, Jie Sun, Haotian Shi, Wei Ma, Jian Sun">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="The Hong Kong Polytechnic University & Tongji University">
  <meta property="og:title" content="SAGE: Steerable Adversarial Scenario Generation through Test-Time Preference Alignment">
  <meta property="og:description" content="SAGE enables fine-grained, test-time control over the trade-off between adversariality and realism in autonomous driving scenario generation without any retraining.">
  <!-- TODO: 替换为您最终的网站URL -->
  <meta property="og:url" content="https://tongnie.github.io/SAGE/">
  <!-- 建议: 使用论文中的Figure 1制作一张1200x630像素的精美预览图 -->
  <meta property="og:image" content="https://tongnie.github.io/SAGE/static/images/Fig_intro.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="SAGE Research Project Preview">
  <meta property="article:published_time" content="2025-09-15T00:00:00.000Z"> 
  <meta property="article:author" content="Tong Nie">
  <meta property="article:author" content="Yuewen Mei">
  <meta property="article:section" content="Artificial Intelligence">
  <meta property="article:tag" content="autonomous driving">

<!--   <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: 替换为您实验室或您自己的Twitter账号 -->
  <meta name="twitter:site" content="@PolyU_HongKong">
  <meta name="twitter:creator" content="@tong_nie">
  <meta name="twitter:title" content="SAGE: Steerable Adversarial Scenario Generation through Test-Time Preference Alignment">
  <meta name="twitter:description" content="SAGE enables fine-grained, test-time control over the trade-off between adversariality and realism in autonomous driving scenario generation without any retraining.">
  <!-- TODO: 确保此URL为您网站的最终URL -->
  <meta name="twitter:image" content="https://tongnie.github.io/SAGE/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="SAGE Research Project Preview">
 -->
  
  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Steerable Adversarial Scenario Generation through Test-Time Preference Alignment">
  <meta name="citation_author" content="Nie, Tong">
  <meta name="citation_author" content="Mei, Yuewen">
  <meta name="citation_author" content="Tang, Yihong">
  <meta name="citation_author" content="He, Junlin">
  <meta name="citation_author" content="Sun, Jie">
  <meta name="citation_author" content="Shi, Haotian">
  <meta name="citation_author" content="Ma, Wei">
  <meta name="citation_author" content="Sun, Jian">
  <meta name="citation_publication_date" content="2026">
  <meta name="citation_conference_title" content="ArXiv">
  <!-- TODO: 论文发布后，替换为最终的PDF链接 -->
  <meta name="citation_pdf_url" content="https://arxiv.org/pdf/<ARXIV_ID_HERE>.pdf">
  
  <title>SAGE: Steerable Adversarial Scenario Generation</title>
  
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="httpshttps://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Steerable Adversarial Scenario Generation through Test-Time Preference Alignment",
    "description": "SAGE enables fine-grained test-time control over the trade-off between adversariality and realism in autonomous driving scenario generation without any retraining.",
    "author": [
      {"@type": "Person", "name": "Tong Nie", "affiliation": {"@type": "Organization", "name": "The Hong Kong Polytechnic University & Tongji University"}},
      {"@type": "Person", "name": "Yuewen Mei", "affiliation": {"@type": "Organization", "name": "Tongji University"}},
      {"@type": "Person", "name": "Yihong Tang", "affiliation": {"@type": "Organization", "name": "McGill University"}},
      {"@type": "Person", "name": "Junlin He", "affiliation": {"@type": "Organization", "name": "The Hong Kong Polytechnic University"}},
      {"@type": "Person", "name": "Jie Sun", "affiliation": {"@type": "Organization", "name": "Tongji University"}},
      {"@type": "Person", "name": "Haotian Shi", "affiliation": {"@type": "Organization", "name": "Tongji University"}},
      {"@type": "Person", "name": "Wei Ma", "affiliation": {"@type": "Organization", "name": "The Hong Kong Polytechnic University"}},
      {"@type": "Person", "name": "Jian Sun", "affiliation": {"@type": "Organization", "name": "Tongji University"}}
    ],
    "datePublished": "2026",
    "publisher": {"@type": "Organization", "name": "ArXiv"},
    "url": "https://tongnie.github.io/SAGE/",
    "image": "https://tongnie.github.io/SAGE/static/images/social_preview.png",
    "keywords": ["adversarial scenario generation", "autonomous driving", "preference alignment", "reinforcement learning"],
    "abstract": "Adversarial scenario generation is a cost-effective approach for the safety assessment of autonomous driving systems. However, existing methods are either overly aggressive, resulting in low realism, or constrained to a fixed trade-off between multiple objectives, lacking the flexibility to adapt to diverse training and testing needs without costly retraining. Here, we reframe the task as a multi-objective preference alignment problem and introduce the first framework for Steerable Adversarial scenario GEneration (SAGE). SAGE enables fine-grained test-time control over the trade-off between adversariality and realism without any retraining. We first propose hierarchical group-based preference optimization, a data-efficient offline alignment method that learns to balance competing objectives by decoupling hard feasibility constraints from soft preferences. Instead of training a fixed model, SAGE fine-tunes two experts on opposing preferences and constructs a continuous spectrum of policies at inference time by linearly interpolating their weights. We provide theoretical justification for this scheme through the lens of linear mode connectivity. Extensive experiments demonstrate that SAGE not only generates scenarios with a superior balance of adversariality and realism but also enables more effective closed-loop training of driving policies.",
    "citation": "@inproceedings{nie2026sage,\n  title={Steerable Adversarial Scenario Generation through Test-Time Preference Alignment},\n  author={Nie, Tong and Mei, Yuewen and Tang, Yihong and He, Junlin and Sun, Jie and Shi, Haotian and Ma, Wei and Sun, Jian},\n  booktitle={ArXiv Preprint},\n  year={2026}\n}"
  }
  </script>
</head>
<body>

<main id="main-content">
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Steerable Adversarial Scenario Generation through Test-Time Preference Alignment</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://tongnie.github.io/" target="_blank">Tong Nie</a><sup>1,2*</sup>,</span>
            <span class="author-block"><a href="#" target="_blank">Yuewen Mei</a><sup>2*</sup>,</span>
            <span class="author-block"><a href="#" target="_blank">Yihong Tang</a><sup>3</sup>,</span>
            <span class="author-block"><a href="#" target="_blank">Junlin He</a><sup>1</sup>,</span>
            <span class="author-block"><a href="#" target="_blank">Jie Sun</a><sup>2</sup>,</span>
            <span class="author-block"><a href="#" target="_blank">Haotian Shi</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://www.polyu.edu.hk/en/cce/people/academic-staff/dr-ma-wei/" target="_blank">Wei Ma</a><sup>1†</sup>,</span>
            <span class="author-block"><a href="https://person.tongji.edu.cn/jason/" target="_blank">Jian Sun</a><sup>2†</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The Hong Kong Polytechnic University,</span>
            <span class="author-block"><sup>2</sup>Tongji University,</span>
            <span class="author-block"><sup>3</sup>McGill University</span>
            <br>
            <span class="author-block">ArXiv Preprint</span>
            <span class="eql-cntrb"><br><small><sup>*</sup>Equal Contribution, <sup>†</sup>Corresponding Authors</small></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- TODO: 论文发布后，请将 <ARXIV_ID_HERE> 替换为真实的ArXiv ID -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/<ARXIV_ID_HERE>.pdf" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/tongnie/SAGE" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fab fa-github"></i></span><span>Code</span>
                </a>
              </span>
              <!-- TODO: 论文发布后，请将 <ARXIV_ID_HERE> 替换为真实的ArXiv ID -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/<ARXIV_ID_HERE>" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="ai ai-arxiv"></i></span><span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%" preload="metadata">
        <source src="static/videos/SAGE_demo_video_upload.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <b>SAGE</b> enables fine-grained control over adversarial scenario generation at test time. By simply adjusting a preference weight <b>without retraining</b>, we can smoothly steer the generated behavior from naturalistic and compliant to challenging and highly adversarial.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Adversarial scenario generation is a cost-effective approach for the safety assessment of autonomous driving systems. However, existing methods are either overly aggressive, resulting in low realism, or constrained to a fixed trade-off between multiple objectives, lacking the flexibility to adapt to diverse training and testing needs without costly retraining. Here, we reframe the task as a multi-objective preference alignment problem and introduce the first framework for <b>S</b>teerable <b>A</b>dversarial scenario <b>GE</b>neration (SAGE). SAGE enables fine-grained test-time control over the trade-off between adversariality and realism without any retraining. We first propose hierarchical group-based preference optimization, a data-efficient offline alignment method that learns to balance competing objectives by decoupling hard feasibility constraints from soft preferences. Instead of training a fixed model, SAGE fine-tunes two experts on opposing preferences and constructs a continuous spectrum of policies at inference time by linearly interpolating their weights. We provide theoretical justification for this scheme through the lens of linear mode connectivity. Extensive experiments demonstrate that SAGE not only generates scenarios with a superior balance of adversariality and realism but also enables more effective closed-loop training of driving policies.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- START: Overview Figure Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column"> 
        <h2 class="title is-3 has-text-centered">Method Overview</h2>
        <div class="content has-text-centered">
          <img src="static/images/Fig_intro.png" alt="Overview of the SAGE framework, showing limitations of existing methods, our solution via test-time alignment, and its application in closed-loop training."/>
          <p class="is-italic pt-2">
            <b>Left</b>: Existing methods suffer from a fixed trade-off between adversariality and realism. <b>Center</b>: Our method, <b>SAGE</b>, reframes the problem as preference alignment. We train two expert models (adversarial and realistic) and interpolate their weights at test time to steer generation across a continuous spectrum of behaviors. <b>Right</b>: This steerability is highly effective for dual curriculum learning in closed-loop training.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- END: Overview Figure Section -->
  
<style>
  .results-carousel .item {
    text-align: center;
  }
  
  .results-carousel .item img {
    height: 400px;
    width: auto;
  }
</style>
<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Results Gallery</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <img src="static/images/Fig_case_weight.png" alt="Visualization of steerable generation from compliant to aggressive cut-in." loading="lazy"/>
          <h2 class="subtitle has-text-centered">
            <b>Test-Time Steerability</b>: Generated trajectories smoothly transition from compliant to aggressive as the adversarial weight increases from 0.0 to 1.0.
          </h2>
        </div>
        <div class="item">
          <img src="static/images/Fig_case_baseline.png" alt="Comparison of generated scenarios between SAGE and other baseline methods." loading="lazy"/>
          <h2 class="subtitle has-text-centered">
            <b>High-Quality Scenarios</b>: SAGE generates challenging yet physically plausible maneuvers, crucial for meaningful safety validation, while baselines often produce awkward or rule-violating trajectories.
          </h2>
        </div>
        <div class="item">
          <img src="static/images/Fig_pareto_front.png" alt="Pareto front comparison showing SAGE's superior trade-off." loading="lazy"/>
          <h2 class="subtitle has-text-centered">
            <b>Superior Trade-off</b>: Our weight-mixing strategy (blue line) traces a superior Pareto front, achieving better realism for any given level of adversariality compared to other mixing strategies.
          </h2>
        </div>
        <div class="item">
          <img src="static/images/Fig_RL_results.png" alt="Training performances of the agent under different scenario generation methods." loading="lazy"/>
          <h2 class="subtitle has-text-centered">
            <b>Enhanced Driving Policy</b>: The agent trained with our SAGE demonstrates a clear advantage across key metrics like reward and completion rate compared to baseline training methods.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End image carousel -->

<!-- START: Results Tables Section -->
<section class="section">
  <div class="container">

    <!-- First Table: Replay Policy -->
    <div class="content">
      <h2 class="title is-3 has-text-centered">Testing Results: Replay Policy</h2>
      <p class="subtitle is-5 has-text-centered">
        Evaluation of adversarial generation methods against the <strong>Replay</strong> policy. Higher is better for Attack Success Rate and Adversarial Reward (↑), while lower is better for penalty metrics (↓).
      </p>
    </div>
    <!-- The container makes the table scrollable on small screens -->
    <div class="table-container">
      <table class="table is-bordered is-hoverable is-fullwidth">
        <thead>
          <tr>
            <th rowspan="2" class="is-vcentered">Methods</th>
            <th rowspan="2" class="is-vcentered">Attack Succ. Rate ↑</th>
            <th rowspan="2" class="is-vcentered">Adv. Reward ↑</th>
            <th colspan="2" class="has-text-centered">Real. Pen. ↓</th>
            <th colspan="2" class="has-text-centered">Map Comp. ↓</th>
            <th colspan="3" class="has-text-centered">Dist. Diff. (WD)</th>
          </tr>
          <tr>
            <th class="has-text-centered">Behav.</th>
            <th class="has-text-centered">Kine.</th>
            <th class="has-text-centered">Crash Obj.</th>
            <th class="has-text-centered">Cross Line</th>
            <th class="has-text-centered">Accel.</th>
            <th class="has-text-centered">Vel.</th>
            <th class="has-text-centered">Yaw</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <th>Rule</th>
            <td>100.00%</td>
            <td>5.048</td>
            <td>2.798</td>
            <td>5.614</td>
            <td>1.734</td>
            <td>7.724</td>
            <td>2.080</td>
            <td>8.546</td>
            <td>0.204</td>
          </tr>
          <tr>
            <th>CAT</th>
            <td>94.85%</td>
            <td>3.961</td>
            <td>8.941</td>
            <td>3.143</td>
            <td>2.466</td>
            <td>9.078</td>
            <td>1.556</td>
            <td>7.233</td>
            <td>0.225</td>
          </tr>
          <tr>
            <th>KING</th>
            <td>40.85%</td>
            <td>2.243</td>
            <td>5.883</td>
            <td>3.434</td>
            <td>3.126</td>
            <td>6.056</td>
            <td>0.972</td>
            <td>255.5</td>
            <td>0.098</td>
          </tr>
          <tr>
            <th>AdvTrajOpt</th>
            <td>70.46%</td>
            <td>2.652</td>
            <td>4.500</td>
            <td>2.775</td>
            <td>2.547</td>
            <td>10.16</td>
            <td>1.754</td>
            <td>6.177</td>
            <td>0.268</td>
          </tr>
          <tr>
            <th>SEAL</th>
            <td>63.93%</td>
            <td>1.269</td>
            <td>3.017</td>
            <td>2.423</td>
            <td>2.732</td>
            <td>11.612</td>
            <td>1.544</td>
            <td>6.959</td>
            <td>0.202</td>
          </tr>
          <!-- SAGE Rows with custom highlighting -->
          <tr class="highlight-gray-1">
            <th>SAGE (w<sub>adv</sub>=0.0)</th>
            <td>16.26%</td>
            <td>1.065</td>
            <td>0.332</td>
            <td>1.998</td>
            <td>0.677</td>
            <td>0.948</td>
            <td>1.459</td>
            <td>9.313</td>
            <td>0.054</td>
          </tr>
          <tr class="highlight-gray-2">
            <th>SAGE (w<sub>adv</sub>=0.5)</th>
            <td>50.41%</td>
            <td>2.523</td>
            <td>0.483</td>
            <td>2.064</td>
            <td>0.755</td>
            <td>0.949</td>
            <td>1.521</td>
            <td>8.471</td>
            <td>0.079</td>
          </tr>
          <tr class="highlight-gray-3">
            <th>SAGE (w<sub>adv</sub>=1.0)</th>
            <td>76.15%</td>
            <td>4.121</td>
            <td>1.429</td>
            <td>2.479</td>
            <td>0.731</td>
            <td>1.084</td>
            <td>2.098</td>
            <td>8.088</td>
            <td>0.184</td>
          </tr>
        </tbody>
      </table>
    </div>

    <!-- Spacer -->
    <br><br>

    <!-- Second Table: RL Policy -->
    <div class="content">
      <h2 class="title is-3 has-text-centered">Testing Results: RL Policy</h2>
      <p class="subtitle is-5 has-text-centered">
        Evaluation of adversarial generation methods against the <strong>RL</strong> policy.
      </p>
    </div>
    <div class="table-container">
      <table class="table is-bordered is-hoverable is-fullwidth">
        <thead>
          <tr>
            <th rowspan="2" class="is-vcentered">Methods</th>
            <th rowspan="2" class="is-vcentered">Attack Succ. Rate ↑</th>
            <th rowspan="2" class="is-vcentered">Adv. Reward ↑</th>
            <th colspan="2" class="has-text-centered">Real. Pen. ↓</th>
            <th colspan="2" class="has-text-centered">Map Comp. ↓</th>
            <th colspan="3" class="has-text-centered">Dist. Diff. (WD)</th>
          </tr>
          <tr>
            <th class="has-text-centered">Behav.</th>
            <th class="has-text-centered">Kine.</th>
            <th class="has-text-centered">Crash Obj.</th>
            <th class="has-text-centered">Cross Line</th>
            <th class="has-text-centered">Accel.</th>
            <th class="has-text-centered">Vel.</th>
            <th class="has-text-centered">Yaw</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <th>Rule</th>
            <td>65.57%</td>
            <td>2.761</td>
            <td>2.180</td>
            <td>113.707</td>
            <td>1.803</td>
            <td>6.148</td>
            <td>10.854</td>
            <td>13.468</td>
            <td>0.336</td>
          </tr>
          <tr>
            <th>CAT</th>
            <td>30.33%</td>
            <td>1.319</td>
            <td>8.191</td>
            <td>3.039</td>
            <td>2.623</td>
            <td>6.967</td>
            <td>1.539</td>
            <td>8.877</td>
            <td>0.187</td>
          </tr>
          <tr>
            <th>KING</th>
            <td>19.14%</td>
            <td>1.148</td>
            <td>2.041</td>
            <td>2.596</td>
            <td>3.114</td>
            <td>5.857</td>
            <td>0.983</td>
            <td>259.132</td>
            <td>0.097</td>
          </tr>
          <tr>
            <th>AdvTrajOpt</th>
            <td>19.40%</td>
            <td>0.992</td>
            <td>4.542</td>
            <td>2.779</td>
            <td>2.459</td>
            <td>9.973</td>
            <td>1.749</td>
            <td>6.187</td>
            <td>0.269</td>
          </tr>
          <tr>
            <th>SEAL</th>
            <td>31.40%</td>
            <td>0.752</td>
            <td>5.871</td>
            <td>2.684</td>
            <td>3.030</td>
            <td>11.984</td>
            <td>1.563</td>
            <td>8.267</td>
            <td>0.267</td>
          </tr>
          <!-- SAGE Rows with custom highlighting -->
          <tr class="highlight-gray-1">
            <th>SAGE (w<sub>adv</sub>=0.0)</th>
            <td>11.20%</td>
            <td>0.722</td>
            <td>0.332</td>
            <td>2.000</td>
            <td>0.738</td>
            <td>0.956</td>
            <td>1.456</td>
            <td>9.344</td>
            <td>0.055</td>
          </tr>
          <tr class="highlight-gray-2">
            <th>SAGE (w<sub>adv</sub>=0.5)</th>
            <td>13.66%</td>
            <td>0.819</td>
            <td>0.496</td>
            <td>2.066</td>
            <td>0.820</td>
            <td>0.820</td>
            <td>1.515</td>
            <td>8.475</td>
            <td>0.080</td>
          </tr>
          <tr class="highlight-gray-3">
            <th>SAGE (w<sub>adv</sub>=1.0)</th>
            <td>28.42%</td>
            <td>1.400</td>
            <td>1.468</td>
            <td>2.496</td>
            <td>0.792</td>
            <td>1.366</td>
            <td>2.098</td>
            <td>8.114</td>
            <td>0.188</td>
          </tr>
        </tbody>
      </table>
    </div>
  </div>
</section>
<!-- END: Results Tables Section -->

<!-- START: Evaluation of Trained RL Policies in the Log-replay (Normal, WOMD) Environments. -->
<section class="section">
  <div class="container">
    <h2 class="title is-3 has-text-centered">Closed-loop RL Training</h2>
    <p class="subtitle is-5 has-text-centered">
      Evaluation of Trained RL Policies in the Log-replay (Normal, WOMD) Environments.
    </p>

    <div class="table-container">
      <table class="table is-bordered is-striped is-fullwidth">
        <thead>
          <tr>
            <th class="is-vcentered">Methods</th>
            <th class="is-vcentered">Reward ↑</th>
            <th class="is-vcentered">Cost ↓</th>
            <th class="is-vcentered">Compl. ↑</th>
            <th class="is-vcentered">Coll. ↓</th>
            <th class="is-vcentered">Ave. Speed ↑</th>
            <th class="is-vcentered">Ave. Jerk ↓</th>
          </tr>
        </thead>
        <tbody>
          <tr class="highlight-gray-2">
            <th>SAGE</th>
            <td><b>51.99 ± 1.22</b></td>
            <td><b>0.48 ± 0.05</b></td>
            <td><b>0.77 ± 0.02</b></td>
            <td>0.16 ± 0.05</td>
            <td><b>9.27 ± 0.03</b></td>
            <td><b>24.97 ± 0.53</b></td>
          </tr>
          <tr>
            <th>CAT</th>
            <td>46.81 ± 4.33</td>
            <td>0.50 ± 0.05</td>
            <td>0.67 ± 0.02</td>
            <td>0.18 ± 0.05</td>
            <td>7.21 ± 0.05</td>
            <td>28.15 ± 1.06</td>
          </tr>
          <tr>
            <th>Replay (No Adv)</th>
            <td>50.16 ± 5.32</td>
            <td>0.50 ± 0.07</td>
            <td>0.72 ± 0.04</td>
            <td>0.23 ± 0.02</td>
            <td>9.03 ± 0.03</td>
            <td>27.53 ± 0.98</td>
          </tr>
          <tr>
            <th>Rule-based Adv</th>
            <td>44.61 ± 3.88</td>
            <td>0.52 ± 0.05</td>
            <td>0.63 ± 0.04</td>
            <td><b>0.13 ± 0.00</b></td>
            <td>6.00 ± 0.10</td>
            <td>28.22 ± 1.44</td>
          </tr>
        </tbody>
      </table>
    </div>
  </div>
</section>
<!-- END: Evaluation of Trained RL Policies in the Log-replay (Normal, WOMD) Environments. -->
  
  
<!-- Add this CSS to the <head> of your HTML, or inside another <style> tag -->
<style>
  /* Center the content of table cells */
  .table th, .table td {
    text-align: center !important;
    vertical-align: middle !important;
  }
  /* Left-align the first column header (Methods) */
  .table th:first-child {
    text-align: left !important;
  }
  /* Custom background colors to match your LaTeX table */
  .highlight-gray-1 {
    background-color: #f2f2f2; /* Corresponds to gray!10 */
  }
  .highlight-gray-2 {
    background-color: #e6e6e6; /* Corresponds to gray!25 */
  }
  .highlight-gray-3 {
    background-color: #d9d9d9; /* Corresponds to gray!40 */
  }
  /* Improve readability of subscript in table headers */
  .table th sub {
    font-size: 0.7em;
  }
</style>

<!-- START: Qualitative Comparison Videos -->
<section class="section">
  <div class="container">
    <h2 class="title is-3 has-text-centered">Qualitative Comparisons</h2>

    <!-- First Row of Videos -->
    <div class="columns is-centered is-vcentered">
      <!-- Video 1: RAW -->
      <div class="column">
        <h3 class="title is-4 has-text-centered">RAW</h3>
        <video playsinline autoplay loop muted src="static/videos/compare_baseline_1_raw.mp4" loading="lazy"></video>
      </div>
      <!-- Video 2: CAT -->
      <div class="column">
        <h3 class="title is-4 has-text-centered">CAT</h3>
        <video playsinline autoplay loop muted src="static/videos/compare_baseline_1_cat.mp4" loading="lazy"></video>
      </div>
      <!-- Video 3: Rule -->
      <div class="column">
        <h3 class="title is-4 has-text-centered">Rule</h3>
        <video playsinline autoplay loop muted src="static/videos/compare_baseline_1_rule.mp4" loading="lazy"></video>
      </div>
      <!-- Video 4: SAGE -->
      <div class="column">
        <h3 class="title is-4 has-text-centered">SAGE</h3>
        <video playsinline autoplay loop muted src="static/videos/compare_baseline_1_sage.mp4" loading="lazy"></video>
      </div>
    </div>

    <!-- Second Row of Videos -->
    <div class="columns is-centered is-vcentered">
      <!-- Video 5: RAW -->
      <div class="column">
        <h3 class="title is-4 has-text-centered">RAW</h3>
        <video playsinline autoplay loop muted src="static/videos/compare_baseline_2_raw.mp4" loading="lazy"></video>
      </div>
      <!-- Video 6: CAT -->
      <div class="column">
        <h3 class="title is-4 has-text-centered">CAT</h3>
        <video playsinline autoplay loop muted src="static/videos/compare_baseline_2_cat.mp4" loading="lazy"></video>
      </div>
      <!-- Video 7: Rule -->
      <div class="column">
        <h3 class="title is-4 has-text-centered">Rule</h3>
        <video playsinline autoplay loop muted src="static/videos/compare_baseline_2_rule.mp4" loading="lazy"></video>
      </div>
      <!-- Video 8: SAGE -->
      <div class="column">
        <h3 class="title is-4 has-text-centered">SAGE</h3>
        <video playsinline autoplay loop muted src="static/videos/compare_baseline_2_sage.mp4" loading="lazy"></video>
      </div>
    </div>
  </div>
</section>
<!-- END: Qualitative Comparison Videos -->

<!-- You should add this small style snippet to your CSS or a <style> tag -->
<style>
  .column video {
    width: 100%;
    height: auto;
    border-radius: 8px; /* Optional: This adds nice rounded corners to your videos */
  }
</style>

  <!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <div class="bibtex-header">
      <h2 class="title">BibTeX</h2>
      <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
        <i class="fas fa-copy"></i>
        <span class="copy-text">Copy</span>
      </button>
    </div>
    <pre id="bibtex-code"><code>@inproceedings{nie2026sage,
  title={Steerable Adversarial Scenario Generation through Test-Time Preference Alignment},
  author={Nie, Tong and Mei, Yuewen and Tang, Yihong and He, Junlin and Sun, Jie and Shi, Haotian and Ma, Wei and Sun, Jian},
  booktitle={ArXiv Preprint},
  year={2026},
  url={https://tongnie.github.io/SAGE/}
}</code></pre>
  </div>
</section>
<!--End BibTex citation -->

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
