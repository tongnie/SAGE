<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="SAGE: Steerable Adversarial Scenario Generation through Test-Time Preference Alignment">
  <meta name="description" content="Official project page for SAGE, a novel framework that enables fine-grained, test-time control over the trade-off between adversariality and realism in autonomous driving scenario generation without any retraining.">
  <meta name="keywords" content="adversarial scenario generation, autonomous driving, safety assessment, preference alignment, reinforcement learning, test-time control, steerable generation">
  <meta name="author" content="Tong Nie, Yuewen Mei, Yihong Tang, Junlin He, Jie Sun, Haotian Shi, Wei Ma, Jian Sun">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="The Hong Kong Polytechnic University & Tongji University">
  <meta property="og:title" content="SAGE: Steerable Adversarial Scenario Generation through Test-Time Preference Alignment">
  <meta property="og:description" content="SAGE enables fine-grained, test-time control over the trade-off between adversariality and realism in autonomous driving scenario generation without any retraining.">
  <!-- TODO: 替换为您最终的网站URL -->
  <meta property="og:url" content="https://tongnie.github.io/SAGE/">
  <!-- 建议: 使用论文中的Figure 1制作一张1200x630像素的精美预览图 -->
  <meta property="og:image" content="https://tongnie.github.io/SAGE/static/images/Fig_intro.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="SAGE Research Project Preview">
  <meta property="article:published_time" content="2025-09-15T00:00:00.000Z"> 
  <meta property="article:author" content="Tong Nie">
  <meta property="article:author" content="Yuewen Mei">
  <meta property="article:section" content="Artificial Intelligence">
  <meta property="article:tag" content="autonomous driving">

<!--   <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: 替换为您实验室或您自己的Twitter账号 -->
  <meta name="twitter:site" content="@PolyU_HongKong">
  <meta name="twitter:creator" content="@tong_nie">
  <meta name="twitter:title" content="SAGE: Steerable Adversarial Scenario Generation through Test-Time Preference Alignment">
  <meta name="twitter:description" content="SAGE enables fine-grained, test-time control over the trade-off between adversariality and realism in autonomous driving scenario generation without any retraining.">
  <!-- TODO: 确保此URL为您网站的最终URL -->
  <meta name="twitter:image" content="https://tongnie.github.io/SAGE/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="SAGE Research Project Preview">
 -->
  
  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Steerable Adversarial Scenario Generation through Test-Time Preference Alignment">
  <meta name="citation_author" content="Nie, Tong">
  <meta name="citation_author" content="Mei, Yuewen">
  <meta name="citation_author" content="Tang, Yihong">
  <meta name="citation_author" content="He, Junlin">
  <meta name="citation_author" content="Sun, Jie">
  <meta name="citation_author" content="Shi, Haotian">
  <meta name="citation_author" content="Ma, Wei">
  <meta name="citation_author" content="Sun, Jian">
  <meta name="citation_publication_date" content="2026">
  <meta name="citation_conference_title" content="ArXiv">
  <!-- TODO: 论文发布后，替换为最终的PDF链接 -->
  <meta name="citation_pdf_url" content="https://arxiv.org/pdf/<ARXIV_ID_HERE>.pdf">
  
  <title>SAGE: Steerable Adversarial Scenario Generation</title>
  
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="httpshttps://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Steerable Adversarial Scenario Generation through Test-Time Preference Alignment",
    "description": "SAGE enables fine-grained test-time control over the trade-off between adversariality and realism in autonomous driving scenario generation without any retraining.",
    "author": [
      {"@type": "Person", "name": "Tong Nie", "affiliation": {"@type": "Organization", "name": "The Hong Kong Polytechnic University & Tongji University"}},
      {"@type": "Person", "name": "Yuewen Mei", "affiliation": {"@type": "Organization", "name": "Tongji University"}},
      {"@type": "Person", "name": "Yihong Tang", "affiliation": {"@type": "Organization", "name": "McGill University"}},
      {"@type": "Person", "name": "Junlin He", "affiliation": {"@type": "Organization", "name": "The Hong Kong Polytechnic University"}},
      {"@type": "Person", "name": "Jie Sun", "affiliation": {"@type": "Organization", "name": "Tongji University"}},
      {"@type": "Person", "name": "Haotian Shi", "affiliation": {"@type": "Organization", "name": "Tongji University"}},
      {"@type": "Person", "name": "Wei Ma", "affiliation": {"@type": "Organization", "name": "The Hong Kong Polytechnic University"}},
      {"@type": "Person", "name": "Jian Sun", "affiliation": {"@type": "Organization", "name": "Tongji University"}}
    ],
    "datePublished": "2026",
    "publisher": {"@type": "Organization", "name": "ArXiv"},
    "url": "https://tongnie.github.io/SAGE/",
    "image": "https://tongnie.github.io/SAGE/static/images/social_preview.png",
    "keywords": ["adversarial scenario generation", "autonomous driving", "preference alignment", "reinforcement learning"],
    "abstract": "Adversarial scenario generation is a cost-effective approach for the safety assessment of autonomous driving systems. However, existing methods are either overly aggressive, resulting in low realism, or constrained to a fixed trade-off between multiple objectives, lacking the flexibility to adapt to diverse training and testing needs without costly retraining. Here, we reframe the task as a multi-objective preference alignment problem and introduce the first framework for Steerable Adversarial scenario GEneration (SAGE). SAGE enables fine-grained test-time control over the trade-off between adversariality and realism without any retraining. We first propose hierarchical group-based preference optimization, a data-efficient offline alignment method that learns to balance competing objectives by decoupling hard feasibility constraints from soft preferences. Instead of training a fixed model, SAGE fine-tunes two experts on opposing preferences and constructs a continuous spectrum of policies at inference time by linearly interpolating their weights. We provide theoretical justification for this scheme through the lens of linear mode connectivity. Extensive experiments demonstrate that SAGE not only generates scenarios with a superior balance of adversariality and realism but also enables more effective closed-loop training of driving policies.",
    "citation": "@inproceedings{nie2026sage,\n  title={Steerable Adversarial Scenario Generation through Test-Time Preference Alignment},\n  author={Nie, Tong and Mei, Yuewen and Tang, Yihong and He, Junlin and Sun, Jie and Shi, Haotian and Ma, Wei and Sun, Jian},\n  booktitle={ArXiv Preprint},\n  year={2026}\n}"
  }
  </script>
</head>
<body>

<main id="main-content">
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Steerable Adversarial Scenario Generation through Test-Time Preference Alignment</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://tongnie.github.io/" target="_blank">Tong Nie</a><sup>1,2*</sup>,</span>
            <span class="author-block"><a href="#" target="_blank">Yuewen Mei</a><sup>2*</sup>,</span>
            <span class="author-block"><a href="#" target="_blank">Yihong Tang</a><sup>3</sup>,</span>
            <span class="author-block"><a href="#" target="_blank">Junlin He</a><sup>1</sup>,</span>
            <span class="author-block"><a href="#" target="_blank">Jie Sun</a><sup>2</sup>,</span>
            <span class="author-block"><a href="#" target="_blank">Haotian Shi</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://www.polyu.edu.hk/en/cce/people/academic-staff/dr-ma-wei/" target="_blank">Wei Ma</a><sup>1†</sup>,</span>
            <span class="author-block"><a href="https://person.tongji.edu.cn/jason/" target="_blank">Jian Sun</a><sup>2†</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The Hong Kong Polytechnic University,</span>
            <span class="author-block"><sup>2</sup>Tongji University,</span>
            <span class="author-block"><sup>3</sup>McGill University</span>
            <br>
            <span class="author-block">ArXiv Preprint</span>
            <span class="eql-cntrb"><br><small><sup>*</sup>Equal Contribution, <sup>†</sup>Corresponding Authors</small></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- TODO: 论文发布后，请将 <ARXIV_ID_HERE> 替换为真实的ArXiv ID -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/<ARXIV_ID_HERE>.pdf" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/tongnie/SAGE" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fab fa-github"></i></span><span>Code</span>
                </a>
              </span>
              <!-- TODO: 论文发布后，请将 <ARXIV_ID_HERE> 替换为真实的ArXiv ID -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/<ARXIV_ID_HERE>" target="_blank" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="ai ai-arxiv"></i></span><span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%" preload="metadata">
        <source src="static/videos/SAGE_demo_video_upload.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <b>SAGE</b> enables fine-grained control over adversarial scenario generation at test time. By simply adjusting a preference weight <b>without retraining</b>, we can smoothly steer the generated behavior from naturalistic and compliant to challenging and highly adversarial.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Adversarial scenario generation is a cost-effective approach for the safety assessment of autonomous driving systems. However, existing methods are either overly aggressive, resulting in low realism, or constrained to a fixed trade-off between multiple objectives, lacking the flexibility to adapt to diverse training and testing needs without costly retraining. Here, we reframe the task as a multi-objective preference alignment problem and introduce the first framework for <b>S</b>teerable <b>A</b>dversarial scenario <b>GE</b>neration (SAGE). SAGE enables fine-grained test-time control over the trade-off between adversariality and realism without any retraining. We first propose hierarchical group-based preference optimization, a data-efficient offline alignment method that learns to balance competing objectives by decoupling hard feasibility constraints from soft preferences. Instead of training a fixed model, SAGE fine-tunes two experts on opposing preferences and constructs a continuous spectrum of policies at inference time by linearly interpolating their weights. We provide theoretical justification for this scheme through the lens of linear mode connectivity. Extensive experiments demonstrate that SAGE not only generates scenarios with a superior balance of adversariality and realism but also enables more effective closed-loop training of driving policies.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- START: Overview Figure Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method Overview</h2>
        <div class="content has-text-centered">
          <!-- 建议：将您论文中的 Figure 1 导出为 overview_figure.png 并放置在此处 -->
          <img src="static/images/Fig_intro.png" alt="Overview of the SAGE framework, showing limitations of existing methods, our solution via test-time alignment, and its application in closed-loop training."/>
          <p class="is-italic pt-2">
            <b>Left</b>: Existing methods suffer from a fixed trade-off between adversariality and realism. <b>Center</b>: Our method, <b>SAGE</b>, reframes the problem as preference alignment. We train two expert models (adversarial and realistic) and interpolate their weights at test time to steer generation across a continuous spectrum of behaviors. <b>Right</b>: This steerability is highly effective for dual curriculum learning in closed-loop training.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- END: Overview Figure Section -->

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Results Gallery</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <!-- 建议：使用论文 Figure 4 (steerability_visualization.png) -->
          <img src="static/images/Fig_case_weight.png" alt="Visualization of steerable generation from compliant to aggressive cut-in." loading="lazy"/>
          <h2 class="subtitle has-text-centered">
            <b>Test-Time Steerability</b>: Generated trajectories smoothly transition from compliant to aggressive as the adversarial weight increases from 0.0 to 1.0.
          </h2>
        </div>
        <div class="item">
          <!-- 建议：使用论文 Figure 9 或 10 (qualitative_comparison.png) -->
          <img src="static/images/Fig_case_baseline_Supplementary_1.png" alt="Comparison of generated scenarios between SAGE and other baseline methods." loading="lazy"/>
          <h2 class="subtitle has-text-centered">
            <b>High-Quality Scenarios</b>: SAGE generates challenging yet physically plausible maneuvers, crucial for meaningful safety validation, while baselines often produce awkward or rule-violating trajectories.
          </h2>
        </div>
        <div class="item">
          <!-- 建议：使用论文 Figure 3(a) (pareto_front_graph.png) -->
          <img src="static/images/Fig_pareto_front.png" alt="Pareto front comparison showing SAGE's superior trade-off." loading="lazy"/>
          <h2 class="subtitle has-text-centered">
            <b>Superior Trade-off</b>: Our weight-mixing strategy (blue line) traces a superior Pareto front, achieving better realism for any given level of adversariality compared to other mixing strategies.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End image carousel -->


  <!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <div class="bibtex-header">
      <h2 class="title">BibTeX</h2>
      <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
        <i class="fas fa-copy"></i>
        <span class="copy-text">Copy</span>
      </button>
    </div>
    <pre id="bibtex-code"><code>@inproceedings{nie2026sage,
  title={Steerable Adversarial Scenario Generation through Test-Time Preference Alignment},
  author={Nie, Tong and Mei, Yuewen and Tang, Yihong and He, Junlin and Sun, Jie and Shi, Haotian and Ma, Wei and Sun, Jian},
  booktitle={ArXiv Preprint},
  year={2026},
  url={https://tongnie.github.io/SAGE/}
}</code></pre>
  </div>
</section>
<!--End BibTex citation -->

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
